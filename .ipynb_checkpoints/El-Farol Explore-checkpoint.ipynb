{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class El_Farol_env:\n",
    "    def __init__(self, NUM_AGENTS = 100, M = 5, N = 20, THR = 60, SEED=42):\n",
    "        np.random.seed(SEED)\n",
    "        self. num_agents = NUM_AGENTS # Number of agents\n",
    "        self.M = M # Number of weeks to remember (memory)\n",
    "        self.N = N # Number of strategies per agent\n",
    "        self.THR = THR # Occupancy threshold\n",
    "        \n",
    "        # Initialize random decision weights for all players\n",
    "        self.weight_mat = np.random.uniform(-1, 1, (self.num_agents, self.N, self.M + 1))\n",
    "        \n",
    "        # Initialize 2*M random instances of weeks of attendance\n",
    "        self.A_M = collections.deque(maxlen = 2*self.M)\n",
    "        for i in range(2*self.M):\n",
    "            self.A_M.append(np.random.randint(0, self.num_agents-1))\n",
    "        \n",
    "        # Initialize the current time step's attendance: \n",
    "        self.A_t = np.random.randint(0, self.num_agents-1)\n",
    "        \n",
    "        # Initialize A circular buffer of M Predictions for attendance for each week\n",
    "        self.S_pred = collections.deque()\n",
    "    \n",
    "    def S_calc(self, w_vec, A_vec):\n",
    "        \n",
    "        S = np.zeros((self.N, self.M))\n",
    "        E = np.zeros((self.N, self.M))\n",
    "        \n",
    "        for i in range(self.N):\n",
    "            for j in range(self.M):\n",
    "                S[i,j] = 100 * (np.dot(w_vec[i,:-1], np.array(A_vec)[M-j:2*M-j]) + w_vec[i,-1])\n",
    "        # Calculating the errors:\n",
    "        for i in range(self.N):\n",
    "            E[i] = S[i,:] - np.array(A_vec)[self.M:]\n",
    "            \n",
    "        return S, E\n",
    "        \n",
    "        \n",
    "    def make_decision(self, w_vec, A_vec, s_ind=None):\n",
    "        '''\n",
    "        # Decision making for one agent:\n",
    "        # Inputs:\n",
    "        #       w_vec: [N x M+1] - Initialized weight vectors (and bias) for one agent's strategies \n",
    "        #       A_vec: [M x 1] - Attendance for the last M steps (Cirular buffer)\n",
    "        #       s_ind: Index {0,N} of the previous best decision strategy, if None, estimate based on memory\n",
    "        # Outputs:\n",
    "        #       d: [0, 1] ~ [DON'T GO, GO]\n",
    "        #       S_guess: Scalar - Estimated number of attendees for current time step (mostly used for troubleshooting)\n",
    "        '''\n",
    "        \n",
    "        S = np.zeros(self.N)\n",
    "        E = np.zeros(self.N)\n",
    "        \n",
    "        if s_ind is None: # The first step\n",
    "            for i in range(self.N):\n",
    "                S[i] = 100 * (np.dot(w_vec[i,:-1], A_vec) + w_vec[i,-1])\n",
    "                E[i] = (np.abs(S[i] - np.array(A_vec))).sum() # Errors in the previous rounds\n",
    "            # Select the strategy with the smallest error:\n",
    "            s_ind = np.argmin(E)\n",
    "            S_guess = S[s_ind]\n",
    "        else:\n",
    "            S_guess = 100 * (np.dot(w_vec[s_ind,:-1], A_vec)) + w_vec[s_ind,-1]\n",
    "        \n",
    "        # Make Decision:\n",
    "        if S_guess <= self.THR: \n",
    "            d = 1 # GO\n",
    "        else: \n",
    "            d = 0 # DON'T GO\n",
    "    \n",
    "        return d, S_guess\n",
    "    \n",
    "    def update_s_star(self, w_vec, A_vec, A_t):\n",
    "        '''\n",
    "        # Decision making for one agent:\n",
    "        # Inputs:\n",
    "        #       w_vec: [N x M+1] - Initialized weight vectors (and bias) for one agent's strategies \n",
    "        #       A_vec: [M x 1] - Attendance for the last M steps (Cirular buffer)\n",
    "        #       A_t: Current time step's attendance\n",
    "        # Outputs:\n",
    "        #       s_ind: Scalar integer: New optimum strategy for the agent\n",
    "        #       S_guess: New estimated number of attendees (mostly used for troubleshooting)\n",
    "        '''\n",
    "        S = np.zeros(self.N)\n",
    "        E = np.zeros(self.N)\n",
    "          \n",
    "        for i in range(self.N):\n",
    "            S[i] = 100 * (np.dot(w_vec[i,:-1], A_vec) + w_vec[i,-1])\n",
    "            E[i] = (np.abs(S[i] - np.array(A_vec))).sum() # Errors in the previous rounds\n",
    "\n",
    "        s_ind = np.argmin(E).astype(int)\n",
    "        S_guess = S[s_ind]\n",
    "        \n",
    "        return s_ind, S_guess\n",
    "        \n",
    "        \n",
    "    def take_steps(self, num_steps=10):\n",
    "        '''\n",
    "        # Simulate multiple weeks of events and decisions\n",
    "        # Inputs:\n",
    "        #       num_steps: Scalar integer - number of weeks to simulate\n",
    "        '''\n",
    "        s_star = np.zeros((self.num_agents, 1)).astype(int)\n",
    "        S_guessed = np.zeros((self.num_agents, 1))\n",
    "        agents_performance = np.zeros((self.num_agents, 1))\n",
    "        A_ts = np.zeros((num_steps, 1)) # Actual number of attendees\n",
    "        d = np.zeros((self.num_agents, 1))\n",
    "        \n",
    "        # Iterating for desired number of steps:\n",
    "        for step_i in range(num_steps):\n",
    "            # Iterating for each agent:\n",
    "            for agent_j in range(self.num_agents):\n",
    "                w_vec = self.weight_mat[agent_j,:,:]\n",
    "                A_vec = self.A_M\n",
    "                if step_i == 0: # Initial step \n",
    "                    s_ind = None\n",
    "                else:\n",
    "                    s_ind = s_star[agent_j]\n",
    "                # Make decision:\n",
    "                d[agent_j], S_guessed[agent_j] = self.make_decision(w_vec=w_vec, A_vec=A_vec, s_ind=s_ind)\n",
    "            \n",
    "            # Calculate A_t\n",
    "            A_t = np.sum(d) # Number of agents who decided to go\n",
    "            A_ts[step_i] = A_t\n",
    "            \n",
    "            # Update circular A_M buffer:\n",
    "            self.A_M.append(A_t)\n",
    "            \n",
    "            # Update S_star for each agent - based on observed A_t\n",
    "            for agent_j in range(self.num_agents):\n",
    "                w_vec = self.weight_mat[agent_j,:,:]\n",
    "                A_vec = self.A_M\n",
    "                s_star[agent_j], _ = self.update_s_star(w_vec=w_vec, A_vec=A_vec, A_t=A_t)\n",
    "                # Estimate performance of each agent\n",
    "                if (S_guessed[agent_j] <= self.THR) and (d[agent_j] == 1): # Correct decision was made\n",
    "                    agents_performance[agent_j] += 1\n",
    "                    \n",
    "        # What do we want the function to retun?\n",
    "        return A_ts, agents_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -356.23506476, -3810.56689168,  2387.64584181],\n",
       "       [-4197.79994961, -1760.67100407,  3724.09157614]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Debugging #2:\n",
    "env = El_Farol_env(NUM_AGENTS=100, M=3, N=2, THR = 60, SEED=42)\n",
    "w_vec = env.weight_mat[1,:,:]\n",
    "A_vec = env.A_M\n",
    "M = 3\n",
    "N = 2\n",
    "S, E = env.S_calc(w_vec=w_vec, A_vec=A_vec)\n",
    "\n",
    "# print(w_vec[0,:-1].shape)\n",
    "# print(np.array(A_vec).shape)\n",
    "# # print(np.array(A_vec)[3:].shape)\n",
    "# # ss = 100 * (np.dot(w_vec[0,:-1], np.array(A_vec)[3-2:-2]) + w_vec[0,-1])\n",
    "# # ss\n",
    "# S = np.zeros((N, M))\n",
    "# E = np.zeros((N, M))\n",
    "\n",
    "# i = 0\n",
    "# j = 1\n",
    "\n",
    "# # A_vec = np.array(A_vec)\n",
    "# # print(A_vec)\n",
    "# # A_vec[M-j:2*M-j]\n",
    "# # A_vec[M-j:-j]\n",
    "# for i in range(N):\n",
    "#     for j in range(M):\n",
    "#         S[i,j] = 100 * (np.dot(w_vec[i,:-1], np.array(A_vec)[M-j:2*M-j]) + w_vec[i,-1])\n",
    "\n",
    "# S\n",
    "S\n",
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([71, 91, 30, 8, 50, 28])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debugging #1:\n",
    "env = El_Farol_env(NUM_AGENTS=100, M=3, N=2, THR = 60, SEED=42)\n",
    "\n",
    "w_vec = env.weight_mat[1,:,:]\n",
    "A_vec = env.A_M\n",
    "\n",
    "S = np.zeros(env.N)\n",
    "E = np.zeros(env.N)\n",
    "for i in range(env.N):\n",
    "    S[i] = 100 * (np.dot(w_vec[i,:-1], A_vec) + w_vec[i,-1])\n",
    "    E[i] = (np.abs(S[i] - np.array(A_vec))).sum()\n",
    "\n",
    "print('W: ', w_vec)\n",
    "print('A:', A_vec)\n",
    "print('S:', S)\n",
    "print('E:', E)\n",
    "\n",
    "# print(env.weight_mat.shape)\n",
    "# print(env.weight_mat[0,:,:].shape)\n",
    "# print(np.squeeze(env.weight_mat[3,:,:]).shape)\n",
    "# print(\"wvec [agent_0] = \", np.squeeze(env.weight_mat[0,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = np.array([0,1,2,3])\n",
    "xx[0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = El_Farol_env()\n",
    "A_ts, agents_performance = env.take_steps(num_steps=100)\n",
    "# print(A_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(A_ts,'-o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(A_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = El_Farol_env()\n",
    "\n",
    "# w_vec = np.squeeze(env.weight_mat[1, :, :])\n",
    "# A_vec = env.A_M\n",
    "# A_t = 44\n",
    "\n",
    "# np.array(A_vec)\n",
    "# d, S_guess = env.make_decision(w_vec=w_vec, A_vec=A_vec, s_ind=None)\n",
    "# print(d)\n",
    "# print(S_guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
