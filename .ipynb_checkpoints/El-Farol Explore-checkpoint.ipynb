{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class El_Farol_env:\n",
    "    def __init__(self, NUM_AGENTS = 100, M = 5, N = 20, THR = 60, SEED=42):\n",
    "        np.random.seed(SEED)\n",
    "        self. num_agents = NUM_AGENTS # Number of agents\n",
    "        self.M = M # Number of weeks to remember (memory)\n",
    "        self.N = N # Number of strategies per agent\n",
    "        self.THR = THR # Occupancy threshold\n",
    "        \n",
    "        # Initialize random decision weights for all players\n",
    "        self.weight_mat = np.random.uniform(-1, 1, (self.num_agents, self.N, self.M + 1))\n",
    "        \n",
    "        # Initialize 2*M random instances of weeks of attendance\n",
    "        self.A_M = collections.deque(maxlen = 2*self.M)\n",
    "        for i in range(2*self.M):\n",
    "            self.A_M.append(np.random.randint(0, self.num_agents-1))\n",
    "        \n",
    "        # Initialize the current time step's attendance: \n",
    "        self.A_t = np.random.randint(0, self.num_agents-1)\n",
    "        \n",
    "        # Initialize A circular buffer of M Predictions for attendance for each week\n",
    "        self.S_pred = collections.deque()\n",
    "    \n",
    "    def make_decision(self, w_vec, A_vec, s_ind=None):\n",
    "        '''\n",
    "        # Decision making for one agent:\n",
    "        # Inputs:\n",
    "        #       w_vec: [N x M+1] - Initialized weight vectors (and bias) for one agent's strategies \n",
    "        #       A_vec: [2M x 1] - Attendance for the last M steps (Cirular buffer)\n",
    "        #       s_ind: Index {0,N} of the previous best decision strategy, if None, estimate based on memory\n",
    "        # Outputs:\n",
    "        #       d: [0, 1] ~ [DON'T GO, GO]\n",
    "        #       S_guess: Scalar - Estimated number of attendees for current time step (mostly used for troubleshooting)\n",
    "        '''\n",
    "        S = np.zeros((self.N, self.M+1))\n",
    "        E = np.zeros(self.N)\n",
    "        \n",
    "        for i in range(self.N):\n",
    "            for j in range(self.M+1):\n",
    "                S[i,j] = 100 * (np.dot(w_vec[i,:-1], np.array(A_vec)[M-j:2*M-j]) + w_vec[i,-1])\n",
    "        \n",
    "#         print(S[0,1:].shape)\n",
    "#         print(np.array(A_vec)[self.M:].shape)\n",
    "        # Calculating the errors:\n",
    "        for i in range(self.N):\n",
    "            E[i] = np.abs(S[i,1:] - np.array(A_vec)[self.M:]).sum() # Don't know A_t, so S[i,0] error can't be calculated yet\n",
    "        \n",
    "        # Making the decision:\n",
    "        if s_ind is None: # Initial time step\n",
    "            # Select the strategy with the smallest error:\n",
    "            s_ind = np.argmin(E)\n",
    "            \n",
    "        S_guess = S[s_ind, 0] # Select the estimate (j=0) for current step\n",
    "        \n",
    "        # Make Decision:\n",
    "        if S_guess <= self.THR: \n",
    "            d = 1 # GO\n",
    "        else: \n",
    "            d = 0 # DON'T GO\n",
    "    \n",
    "        return d, S_guess\n",
    "         \n",
    "    \n",
    "    def update_s_star(self, w_vec, A_vec, A_t):\n",
    "        '''\n",
    "        # Decision making for one agent:\n",
    "        # Inputs:\n",
    "        #       w_vec: [N x M+1] - Initialized weight vectors (and bias) for one agent's strategies \n",
    "        #       A_vec: [M x 1] - Attendance for the last M steps (Cirular buffer)\n",
    "        #       A_t: Current time step's attendance\n",
    "        # Outputs:\n",
    "        #       s_ind: Scalar integer: New optimum strategy for the agent\n",
    "        #       S_guess: New estimated number of attendees (mostly used for troubleshooting)\n",
    "        '''\n",
    "        S = np.zeros(self.N)\n",
    "        E = np.zeros(self.N)\n",
    "        \n",
    "        for i in range(self.N):\n",
    "            for j in range(self.M+1):\n",
    "                S[i,j] = 100 * (np.dot(w_vec[i,:-1], np.array(A_vec)[M-j:2*M-j]) + w_vec[i,-1])\n",
    "                \n",
    "        for i in range(self.N):\n",
    "            E[i] = np.abs(S[i,1:] - np.array(A_vec)[self.M:]).sum() # Don't know A_t, so S[i,0] error can't be calculated yet\n",
    "            # Add the error for the current step:\n",
    "            E[i] += np.abs(S[i,0] - A_t)\n",
    "        \n",
    "        s_ind = np.argmin(E).astype(int)\n",
    "        S_guess = S[s_ind]\n",
    "        \n",
    "        return s_ind, S_guess\n",
    "        \n",
    "        \n",
    "    def take_steps(self, num_steps=10):\n",
    "        '''\n",
    "        # Simulate multiple weeks of events and decisions\n",
    "        # Inputs:\n",
    "        #       num_steps: Scalar integer - number of weeks to simulate\n",
    "        '''\n",
    "        s_star = np.zeros((self.num_agents, 1)).astype(int)\n",
    "        S_guessed = np.zeros((self.num_agents, 1))\n",
    "        agents_performance = np.zeros((self.num_agents, 1))\n",
    "        A_ts = np.zeros((num_steps, 1)) # Actual number of attendees\n",
    "        d = np.zeros((self.num_agents, 1))\n",
    "        \n",
    "        # Iterating for desired number of steps:\n",
    "        for step_i in range(num_steps):\n",
    "            # Iterating for each agent:\n",
    "            for agent_j in range(self.num_agents):\n",
    "                w_vec = self.weight_mat[agent_j,:,:]\n",
    "                A_vec = self.A_M\n",
    "                if step_i == 0: # Initial step \n",
    "                    s_ind = None\n",
    "                else:\n",
    "                    s_ind = s_star[agent_j]\n",
    "                # Make decision:\n",
    "                d[agent_j], S_guessed[agent_j] = self.make_decision(w_vec=w_vec, A_vec=A_vec, s_ind=s_ind)\n",
    "            \n",
    "            # Calculate A_t\n",
    "            A_t = np.sum(d) # Number of agents who decided to go\n",
    "            A_ts[step_i] = A_t\n",
    "            \n",
    "            # Update circular A_M buffer:\n",
    "            self.A_M.append(A_t)\n",
    "            \n",
    "            # Update S_star for each agent - based on observed A_t\n",
    "            for agent_j in range(self.num_agents):\n",
    "                w_vec = self.weight_mat[agent_j,:,:]\n",
    "                A_vec = self.A_M\n",
    "                s_star[agent_j], _ = self.update_s_star(w_vec=w_vec, A_vec=A_vec, A_t=A_t)\n",
    "                # Estimate performance of each agent\n",
    "                if (S_guessed[agent_j] <= self.THR) and (d[agent_j] == 1): # Correct decision was made\n",
    "                    agents_performance[agent_j] += 1\n",
    "                    \n",
    "        # What do we want the function to retun?\n",
    "        return A_ts, agents_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 4)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n",
      "(3,)\n",
      "[[ -348.23506476 -3760.56689168  2415.64584181  2440.24301885]\n",
      " [-4189.79994961 -1710.67100407  3752.09157614 -2487.11198108]]\n",
      "[8546.45575233 7935.87456129]\n",
      "-4189.799949606113\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Debugging #2:\n",
    "env = El_Farol_env(NUM_AGENTS=100, M=3, N=2, THR = 60, SEED=42)\n",
    "w_vec = env.weight_mat[1,:,:]\n",
    "A_vec = env.A_M\n",
    "M = 3\n",
    "N = 2\n",
    "S, E, d, S_guess = env.make_decision(w_vec=w_vec, A_vec=A_vec, s_ind=None)\n",
    "\n",
    "print(S)\n",
    "print(E)\n",
    "print(S_guess)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debugging #1:\n",
    "env = El_Farol_env(NUM_AGENTS=100, M=3, N=2, THR = 60, SEED=42)\n",
    "\n",
    "w_vec = env.weight_mat[1,:,:]\n",
    "A_vec = env.A_M\n",
    "\n",
    "S = np.zeros(env.N)\n",
    "E = np.zeros(env.N)\n",
    "for i in range(env.N):\n",
    "    S[i] = 100 * (np.dot(w_vec[i,:-1], A_vec) + w_vec[i,-1])\n",
    "    E[i] = (np.abs(S[i] - np.array(A_vec))).sum()\n",
    "\n",
    "print('W: ', w_vec)\n",
    "print('A:', A_vec)\n",
    "print('S:', S)\n",
    "print('E:', E)\n",
    "\n",
    "# print(env.weight_mat.shape)\n",
    "# print(env.weight_mat[0,:,:].shape)\n",
    "# print(np.squeeze(env.weight_mat[3,:,:]).shape)\n",
    "# print(\"wvec [agent_0] = \", np.squeeze(env.weight_mat[0,:,:]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
